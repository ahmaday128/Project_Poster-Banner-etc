{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_DeepLearning_AudioBooks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMdRJQmeK0eLqDmsk2VdJcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmadyamin93/Project_Poster-Banner-etc/blob/master/MachineLearning_AudioBooks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGC_QD5uXgZ"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJNtNcoQt_3h"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQlHAs6ZwUPE",
        "outputId": "7cda49c7-c7bc-4acb-bbcf-12fb39574763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIu8j8lnufdH"
      },
      "source": [
        "**Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-jAQJyKudzH"
      },
      "source": [
        "npz = np.load('/content/gdrive/My Drive/Colab_Notebooks/Audiobooks_data_train.npz')\n",
        "\n",
        "train_inputs = npz['inputs'].astype(np.float)\n",
        "train_targets = npz['targets'].astype(np.int)\n",
        "\n",
        "npz = np.load('/content/gdrive/My Drive/Colab_Notebooks/Audiobooks_data_validation.npz')\n",
        "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
        "\n",
        "npz = np.load('/content/gdrive/My Drive/Colab_Notebooks/Audiobooks_data_test.npz')\n",
        "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBKAWD4UxIzJ"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01hfdO3lwAIk",
        "outputId": "6a054973-77b1-401d-a79e-b0e2d1a44cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set the input and output sizes\n",
        "input_size = 10\n",
        "output_size = 2\n",
        "# Use same hidden layer size for both hidden layers. Not a necessity.\n",
        "hidden_layer_size = 50\n",
        "    \n",
        "# define how the model will look like\n",
        "model = tf.keras.Sequential([\n",
        "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
        "    # it takes several arguments, but the most important ones for us are the hidden_layer_size and the activation function\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
        "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
        "    # the final layer is no different, we just make sure to activate it with softmax\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
        "])\n",
        "\n",
        "\n",
        "### Choose the optimizer and the loss function\n",
        "\n",
        "# we define the optimizer we'd like to use, \n",
        "# the loss function, \n",
        "# and the metrics we are interested in obtaining at each iteration\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "### Training\n",
        "# That's where we train the model we have built.\n",
        "\n",
        "# set the batch size\n",
        "batch_size = 100\n",
        "\n",
        "# set a maximum number of training epochs\n",
        "max_epochs = 100\n",
        "\n",
        "# set an early stopping mechanism\n",
        "# let's set patience=2, to be a bit tolerant against random validation loss increases\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
        "\n",
        "# fit the model\n",
        "# note that this time the train, validation and test data are not iterable\n",
        "model.fit(train_inputs, # train inputs\n",
        "          train_targets, # train targets\n",
        "          batch_size=batch_size, # batch size\n",
        "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
        "          # callbacks are functions called by a task when a task is completed\n",
        "          # task here is to check if val_loss is increasing\n",
        "          callbacks=[early_stopping], # early stopping\n",
        "          validation_data=(validation_inputs, validation_targets), # validation data\n",
        "          verbose = 2 # making sure we get enough information about the training process\n",
        "          )  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 - 0s - loss: 0.5021 - accuracy: 0.8122 - val_loss: 0.3924 - val_accuracy: 0.8770\n",
            "Epoch 2/100\n",
            "36/36 - 0s - loss: 0.3536 - accuracy: 0.8720 - val_loss: 0.3318 - val_accuracy: 0.8837\n",
            "Epoch 3/100\n",
            "36/36 - 0s - loss: 0.3160 - accuracy: 0.8829 - val_loss: 0.3073 - val_accuracy: 0.8881\n",
            "Epoch 4/100\n",
            "36/36 - 0s - loss: 0.2965 - accuracy: 0.8885 - val_loss: 0.2917 - val_accuracy: 0.8949\n",
            "Epoch 5/100\n",
            "36/36 - 0s - loss: 0.2826 - accuracy: 0.8924 - val_loss: 0.2820 - val_accuracy: 0.8926\n",
            "Epoch 6/100\n",
            "36/36 - 0s - loss: 0.2708 - accuracy: 0.8944 - val_loss: 0.2754 - val_accuracy: 0.8971\n",
            "Epoch 7/100\n",
            "36/36 - 0s - loss: 0.2643 - accuracy: 0.8983 - val_loss: 0.2699 - val_accuracy: 0.9038\n",
            "Epoch 8/100\n",
            "36/36 - 0s - loss: 0.2599 - accuracy: 0.8994 - val_loss: 0.2640 - val_accuracy: 0.9083\n",
            "Epoch 9/100\n",
            "36/36 - 0s - loss: 0.2553 - accuracy: 0.9014 - val_loss: 0.2638 - val_accuracy: 0.9016\n",
            "Epoch 10/100\n",
            "36/36 - 0s - loss: 0.2503 - accuracy: 0.9022 - val_loss: 0.2622 - val_accuracy: 0.9016\n",
            "Epoch 11/100\n",
            "36/36 - 0s - loss: 0.2497 - accuracy: 0.9044 - val_loss: 0.2598 - val_accuracy: 0.9060\n",
            "Epoch 12/100\n",
            "36/36 - 0s - loss: 0.2453 - accuracy: 0.9053 - val_loss: 0.2554 - val_accuracy: 0.9060\n",
            "Epoch 13/100\n",
            "36/36 - 0s - loss: 0.2434 - accuracy: 0.9075 - val_loss: 0.2599 - val_accuracy: 0.9060\n",
            "Epoch 14/100\n",
            "36/36 - 0s - loss: 0.2400 - accuracy: 0.9064 - val_loss: 0.2545 - val_accuracy: 0.9083\n",
            "Epoch 15/100\n",
            "36/36 - 0s - loss: 0.2364 - accuracy: 0.9089 - val_loss: 0.2570 - val_accuracy: 0.9083\n",
            "Epoch 16/100\n",
            "36/36 - 0s - loss: 0.2359 - accuracy: 0.9100 - val_loss: 0.2554 - val_accuracy: 0.9083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6b20619b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA_JVZyfy2n4"
      },
      "source": [
        "**Test The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms5ZsBO_xnZx",
        "outputId": "2d307a45-5fe5-4967-eb0b-80f51c93ed4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC4kPgb1y70K",
        "outputId": "834abb6b-50fb-4f5f-a3ea-8131e6e565a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test loss: 0.27. Test accuracy: 89.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGnApKU0zCR-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}